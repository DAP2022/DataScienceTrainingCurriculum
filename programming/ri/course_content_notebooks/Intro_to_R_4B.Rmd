---
title: "Intro_to_R_4B"
output: html_document
date: "2024-03-08"
---
We Haven't had any statistics training yet, but, despite this, we will bravely begin to address uncertainty in our data sets.

1. Often, in statistics we are estimating the population mean by using a sample. When we calculate the sample mean, we want to put an interval on that estimate that we have confidence contains the true population mean value.  

2. Using the GA_Module4 dataset.
a. Use the *t distribution* and *t test* to get the 95% Confidence interval for the difference between the mean weight among the different Great Apes. Keep in mind that that * t distribution* has assumptions that are not necessary met by this particular data set, but we will carefully define the *t distribution* - and its assumptions - later on (probably in R II when we will likely introduce the various statistical tests --- since that is one of the major uses for R!). 
b. Summary statistics commands(mean(), sd(), median(),summary(), quantiles)
c. Investigate the properties of boxplots 

3. Using a direct input data set (the ten salaries are given in the .rmd file below)
a. Deploy summary statistics, including quantiles
b. Answer the question: Can ggplot2 help us plot uncertainty? 

4. (IF time) Learn basic simulation of Bootstraps: What happens when we can't capture uncertainty using known out-of-the-box distributions? A gentle introduction to some (just a tiny amount!) programming using R.

We read in the files (this is a file of only Chimpanzees and we will compare it to the file of a bunch of different species of Great Apes):
```{r}

```

This cell just ensures that we have the column names correct! And reminds us of these functions...
```{r}

```
Basic data exploration - remember that it is good programming to always 'park' the results of your function into a variable that can be called later:  
```{r}
# mean and standard deviation and median of all the Great Apes that were included
# -----------------------
# remember that there is often a difference between the values you get with the mean and 
# with the median - especially if there is a skew.
# -----------------------

```
Let's display these two files: 
first up, GA (this is sort of cheating because there is only one category but boxplots can be informative about spread so it can provide some useful preliminary information)
```{r}
# We can compare the weights of all the great apes to the weights of just the chimpanzees. 

```
```{r}
#We can break down the weights of the various species of great apes
#boxplot(GA_Weight~GA_Species, main="Different types of Great Apes Species")

````

```{r}
# We can repeat this analysis for the Bumpus data set

```
```{r}

```
_____
# Below this is t-test and bootstrap
# These are optional
-----
Now, we will use the t.test() to obtain a 95% confidence interval for the true difference in means of the weight of the "all Great Apes" and the "Chimpanzees" datasets. 95% is the default argument in the t.tests but it is explicitly included in the chunk below so you can see it. __With a two sample t.test, you are comparing the mean of one data set (Great Apes set) to the mean of another data set (Only Chimpanzee data set) to see if there is a statistically significant difference between them.__ In our case, the mean of the Chimpanzee set is smaller than the mean of the Great Apes data set so the confidence interval of the difference between them will be negative. If we swapped the two arguments around, the difference would be positive. (shown here as ttest_1 and ttest_2). This is a tangent but notice that, as the default, R uses the Welch approx two sample t-test. That isn't entirely appropriate unless variances between the two groups are vastly different but it is a conservative strategy- and it is better than using the two sample t test as a default in case your variances are very different - so many statistical programming languages use Welch as a default. For people with some experience (or Joy!) in statistical training, that was a little tidbit for you. 
```{r}
GA_ttest_1<-t.test(Weight,GA_Weight, conf.level = 0.95)
#call the variable where we have stored the results of the t-test
GA_ttest_1
#run the second t-test where we swap the order of two samples
Chimp_ttest_2<-t.test(GA_Weight,Weight, conf.level = 0.95)
#call the variable where we have stored the results of the t-test
Chimp_ttest_2
```
The quantile function is another way to double check your values in your boxplot and the results of the median() function: 
```{r}
# we specify the bottom 5 and top 5% values by using the c() function
Top_bottom_5<-quantile(GA_Weight,c(0.05,0.95))
Top_bottom_5
# without specifying the particular quantiles that you want, the quantile function will 
# return 0, 25, 50, 75, 100%.
quantile(GA_Weight)
# the 50% percentile should correspond the median value in the boxplot and in the value 
# produced by the median() function.
```

Now, we move on to our directly inputted data: 

Here are ten salaries of recent graduates of X college. First, we want to examine the data set.
```{r}
# input data using c()
salaries<-c(44617,7066,17594,2726,1178,18898,5033,37151,4514,4000)
# put a happy little plot here 

```
Now we are going to use the **t distribution** to the calculate 90% confidence interval values. We haven't discussed the **t distribution** yet, but for 90% confidence interval ends, the t distribution is symmetric so we use the qt() function with the arguments 0.95 on the high end and 0.05 on the low end. The **t distribution** is robust to many violations of its assumptions but, as we will see later on (chapters 5, 6 and 7), we will need to test the assumptions of data sets before we apply the **t distribution**. NB: qt() is a function that gives us the quantiles if our data set had a *t distribution* and shouldn't be used with other distributions that are not symmetric (ie. Chi squared distributions).

```{r}
# t distribution has n-1 degrees of freedom. length(x) gives us 'n' so we have to subtract
# 1 to get the degrees of freedom. 
CI<-qt(c(0.05,0.95),length(salaries)-1)
# translate this cut off value that defines the top and bottom 5% to a standard error
StError<-qt(0.95,9)*(sd(salaries)/sqrt(length(salaries)))
# in order to use ggplot2 to graph the errorbars/CI, we need to calculate the upper limit 
# and the lower limit of the SE ourselves.
Upperlimit<-mean(salaries)+StError
Lowerlimit<-mean(salaries)-StError
Upperlimit
Lowerlimit
```

#### The following section is really only if we have extra time. I am including it since some of you will already have some experience with R and might appreciate the extra depth
-------

Finally: Bootstrap! Bootstraps are used to determine the confidence intervals for data that is not well behaved (it isn't normally distributed), or that can't be replicated (such as constructing phylogenies - really , a disproportionate amount of statistical thinking is embedded in phylogeny construction. But sometimes trying to solve one problem, also solves other problems!). Basically: when we have no other (easier) tools to use, we need to simulate values. 
```{r}
# create an empty list that we will fill with simulated mean values
bstrap<-c()
# ensure that it is empty by calling it before the loop has run
bstrap
# 1000 replicates of picking 10 values, from the 10 salary data points, at a time to 
# populate the ten salaries that we are expecting. Since we are replacing the value on each
# pick, it is entirely possible that in any given ten salaries, you have picked one 
# multiple times, ie. 17594 
for(i in 1:1000){
  bsample<-sample(salaries,10,replace=TRUE)
  # the sample function is a built in function that samples the data randomly. So for any 
  # one run, you might have ten salaries that look like this: 
  # 17594,5033,17594,18898,44617,2726,1178,,5033,37151,4000
  # where some salaries from the original data set are represented more than 
  # once and some are not represented at all.  
  bestimate<-mean(bsample)
  # populate that originally empty list
  bstrap<-c(bstrap,bestimate)}
# calculate the quantiles of the bstrap
# in contrast to the qt() which uses the t-distribution to approximate what the data would
# look like if it conformed to a t distribution, the quantile of the bstrap orders the data
# from smallest to largest out of the 1000 rounds that we did above and then takes, in this
# case, the 50th value (corresponds to bottom 0.05) and the 950th value which corresponds 
# to top 5% of the values in the 1000 element bstrap vector
quantile(bstrap,0.05)
quantile(bstrap,0.95)
quantile(bstrap,0.025)
quantile(bstrap,0.975)
#if we call the bstrap variable, it will give us all 1000 values. 
bstrap
```

Remember to detach!
```{r}
detach(GA_Module4)
```
